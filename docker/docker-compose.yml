version: '3.8'

services:
  shopping-helper-crawler:
    container_name: shopping-helper-crawler
    build:
      context: ..
      dockerfile: docker/Dockerfile
    restart: unless-stopped

    # 보안: 권한 제한
    security_opt:
      - no-new-privileges:true
    cap_drop:
      - ALL
    read_only: false  # 데이터 쓰기 필요

    # 리소스 제한
    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G
        reservations:
          cpus: '0.5'
          memory: 512M

    environment:
      - TZ=Asia/Seoul
      - YOUTUBE_API_KEY=${YOUTUBE_API_KEY}
      - GEMINI_API_KEY=${GEMINI_API_KEY}
      - AWS_ACCESS_KEY_ID=${AWS_ACCESS_KEY_ID}
      - AWS_SECRET_ACCESS_KEY=${AWS_SECRET_ACCESS_KEY}
      - AWS_DEFAULT_REGION=ap-southeast-2
      - S3_BUCKET=notam-korea-data

    volumes:
      - ./data:/app/data
      - ./logs:/app/data/logs

    # 6시간마다 실행 루프
    command: >
      sh -c "while true; do
        echo '[$(date)] Starting crawler...';
        python crawler/scheduler.py --force --max-videos 30;
        python crawler/s3_uploader.py;
        echo '[$(date)] Sleeping 6 hours...';
        sleep 21600;
      done"

    # 헬스체크
    healthcheck:
      test: ["CMD", "python", "-c", "print('healthy')"]
      interval: 30s
      timeout: 10s
      retries: 3
      start_period: 10s

    # 로깅 설정
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # 다이소 이미지 수집기
  daiso-image-collector:
    container_name: daiso-image-collector
    image: mcr.microsoft.com/playwright/python:v1.40.0-jammy
    restart: "no"

    security_opt:
      - no-new-privileges:true

    deploy:
      resources:
        limits:
          cpus: '2'
          memory: 2G

    environment:
      - TZ=Asia/Seoul
      - DATA_PATH=/app/data/daiso.json
      - IMAGE_DIR=/app/images/daiso
      - GIT_REPO=${GIT_REPO}
      - GIT_TOKEN=${GIT_TOKEN}

    volumes:
      - ../crawler/daiso_image_collector.py:/app/daiso_image_collector.py:ro
      - ../web/public/data:/app/data:ro
      - ./images/daiso:/app/images/daiso
      - ../.git:/app/.git

    working_dir: /app

    command: >
      sh -c "pip install playwright &&
             python daiso_image_collector.py"

    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

networks:
  default:
    name: shopping-helper-network
